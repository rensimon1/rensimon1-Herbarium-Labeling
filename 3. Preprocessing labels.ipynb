{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36510,"status":"ok","timestamp":1736093766542,"user":{"displayName":"Romain","userId":"08376042861121468199"},"user_tz":-60},"id":"9fg-VH7Tzw8d","outputId":"5641328c-2542-4bb9-b016-3e7931bd176e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Collecting easyocr\n","  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.20.1+cu121)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.25.0)\n","Collecting python-bidi (from easyocr)\n","  Downloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n","Collecting pyclipper (from easyocr)\n","  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n","Collecting ninja (from easyocr)\n","  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.36.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.12.12)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n","Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-bidi, pyclipper, pytesseract, ninja, easyocr\n","Successfully installed easyocr-1.7.2 ninja-1.11.1.3 pyclipper-1.3.0.post6 pytesseract-0.3.13 python-bidi-0.6.3\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 4,816 kB of archives.\n","After this operation, 15.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n","Fetched 4,816 kB in 1s (9,407 kB/s)\n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 123634 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n","Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n","Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.25.0)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n","Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.12.12)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n"]}],"source":["!pip install pytesseract easyocr\n","!apt-get install tesseract-ocr\n","!pip install --upgrade scikit-image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqsXDZH1jccA"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import os\n","import zipfile\n","from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83682,"status":"ok","timestamp":1736093850218,"user":{"displayName":"Romain","userId":"08376042861121468199"},"user_tz":-60},"id":"xNU4yJkqlD7Y","outputId":"241ec259-965c-4db9-c676-47858e207bfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')\n","\n","# Fonction pour supprimer un fichier/dossier s'il existe\n","def remove_if_exists(path):\n","    if os.path.exists(path):\n","        if os.path.isdir(path):\n","            os.rmdir(path)  # Supprimer un dossier\n","        else:\n","            os.remove(path)  # Supprimer un fichier\n","        print(f\"{path} a été supprimé.\")\n","    else:\n","        print(f\"{path} n'existe pas.\")\n","\n","extracted_etiquette_folder = '/content/drive/MyDrive/Project/Deep Learning/cropped_labels'\n"]},{"cell_type":"markdown","metadata":{"id":"gXchIqgx9va5"},"source":["#Fonctions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3-ANKvhr2ku"},"outputs":[],"source":["# Fonction pour afficher avant et après\n","def display_before_after(before, after, title_before, title_after):\n","    plt.figure(figsize=(12, 6))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(before, cmap='gray')\n","    plt.title(title_before)\n","    plt.axis('off')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(after, cmap='gray')\n","    plt.title(title_after)\n","    plt.axis('off')\n","\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"2im2dEVA4BLi"},"source":["##Deskew"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93gEcNmUxo94"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","def deskew_image(image):\n","    # Convertir l'image en niveaux de gris\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Appliquer un flou pour lisser l'image\n","    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","    # Détecter les bords avec Canny\n","    edges = cv2.Canny(blurred, 50, 150)\n","\n","    # Détection des lignes avec Hough\n","    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)\n","\n","    if lines is not None:\n","        # Calculer l'angle moyen des lignes détectées\n","        angles = []\n","        for line in lines:\n","            x1, y1, x2, y2 = line[0]\n","            # Calculer l'angle de chaque ligne\n","            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n","            angles.append(angle)\n","\n","        # Calculer la médiane des angles\n","        angle = np.median(angles)\n","\n","    else:\n","        angle = 0  # Si aucune ligne n'est détectée, pas de rotation nécessaire\n","\n","    # Appliquer la rotation pour corriger l'inclinaison\n","    (h, w) = image.shape[:2]\n","    center = (w // 2, h // 2)\n","    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n","    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","\n","    return rotated_image\n"]},{"cell_type":"markdown","metadata":{"id":"6InDp41I9k5x"},"source":["##Binarisation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9EtA0GH9iMC"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from skimage.filters import threshold_sauvola\n","\n","def sauvola_binarization(image, window_size=25, k=0.2, R=128):\n","    \"\"\"\n","    Applique la binarisation de Sauvola à une image en utilisant scikit-image.\n","\n","    Parameters:\n","        image (numpy array): L'image à traiter (en niveaux de gris ou couleur).\n","        window_size (int): Taille de la fenêtre pour calculer le seuil local.\n","        k (float): Facteur de pondération pour la variance locale.\n","        R (float): Paramètre de normalisation (par défaut 128, recommandé par Sauvola).\n","\n","    Returns:\n","        numpy array: Image binarisée.\n","    \"\"\"\n","    # Convertir l'image en niveaux de gris si nécessaire\n","    if len(image.shape) == 3:  # Si l'image est en couleur\n","        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    else:\n","        gray_image = image\n","\n","    # Calculer le seuil local en utilisant Sauvola\n","    sauvola_thresh = threshold_sauvola(gray_image, window_size=window_size, k=k, r=R)\n","\n","    # Appliquer la binarisation\n","    binarized_image = (gray_image > sauvola_thresh).astype(np.uint8)\n","\n","    return 1 - binarized_image"]},{"cell_type":"markdown","metadata":{"id":"tZFd2l7N4Edy"},"source":["##Orienter image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmXos0CFQH8p"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import pytesseract\n","\n","# Fonction pour détecter et corriger l'orientation de l'image en utilisant la détection de lignes de Hough\n","def correct_image_orientation_using_lines(image, angle_threshold=1.0):\n","    # Convertir l'image en niveaux de gris\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Appliquer un flou pour réduire le bruit\n","    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","    # Détecter les bords avec Canny\n","    edges = cv2.Canny(blurred, 50, 150, apertureSize=3)\n","\n","    # Appliquer la transformation de Hough pour détecter les lignes\n","    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n","\n","    # Si aucune ligne n'est détectée, retourner l'image sans modification\n","    if lines is None:\n","        print(\"Aucune ligne détectée.\")\n","        return image, 0\n","\n","    # Calculer l'angle moyen des lignes détectées\n","    angles = []\n","    for line in lines:\n","        rho, theta = line[0]\n","        angle = np.degrees(theta) - 90  # L'angle est mesuré à partir de l'axe horizontal\n","        angles.append(angle)\n","\n","    # Calculer l'angle moyen\n","    mean_angle = np.mean(angles)\n","    print(f\"Angle moyen détecté : {mean_angle:.2f}°\")\n","\n","    # Si l'angle est supérieur au seuil, on considère qu'il faut corriger l'orientation\n","    if abs(mean_angle) > angle_threshold:\n","        print(f\"L'image est inclinée de {mean_angle} degrés, la rotation est nécessaire.\")\n","        rows, cols = image.shape[:2]\n","        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), mean_angle, 1)\n","        image = cv2.warpAffine(image, M, (cols, rows))\n","    else:\n","        print(f\"L'image est correctement orientée (angle {mean_angle:.2f}°).\")\n","\n","    return image, mean_angle\n","\n","def correct_image_orientation_with_tesseract(image):\n","    # Convertir l'image en niveaux de gris\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    gray = sauvola_binarization(gray, window_size=35, k=0.08, R=128)\n","\n","\n","\n","    # Utiliser pytesseract pour obtenir l'orientation de l'image\n","    osd = pytesseract.image_to_osd(gray)\n","\n","    # Extraire l'angle de rotation de l'OSD (Orientation and Script Detection)\n","    rotation_angle = int(osd.split('\\n')[0].split(':')[1].strip())\n","    print(f\"Angle de rotation détecté par Tesseract : {rotation_angle}°\")\n","\n","    # Appliquer la rotation si nécessaire\n","    if rotation_angle != 0:\n","        rows, cols = image.shape[:2]\n","        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle, 1)\n","        image = cv2.warpAffine(image, rotation_matrix, (cols, rows))\n","\n","    return image, rotation_angle\n","\n","# Exemple d'utilisation\n","# import os\n","\n","# # Supposons que vous avez déjà chargé l'image comme suit :\n","# image_path = os.path.join(extracted_etiquette_folder, image_files[2])\n","# image = cv2.imread(image_path)\n","# # image = sauvola_binarization(image, window_size=35, k=0.08, R=128)\n","\n","\n","# # Exemple d'utilisation\n","# import os\n","\n","# # Supposons que vous avez déjà chargé l'image comme suit :\n","# image_path = os.path.join(extracted_etiquette_folder, image_files[0])\n","# image = cv2.imread(image_path)\n","\n","# # Effectuer les rotations de 45° cumulées à chaque itération\n","# for i in range(4):  # On fait pivoter l'image de 45° à chaque itération, pour un total de 360°\n","#     rotated_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)  # Rotation de 90° chaque fois\n","#     image = rotated_image  # Met à jour l'image pour la prochaine itération\n","\n","#     corrected_image, angle = correct_image_orientation_with_tesseract(rotated_image)  # Seuil de 0.2° pour éviter des corrections inutiles\n","\n","#     print(f\"Rotation {90*(i+1)}° - Angle moyen calculé : {angle:.2f}°\")\n","\n","#     # Afficher l'image avant et après correction\n","#     display_before_after(rotated_image, corrected_image, f\"Avant correction {90*(i+1)}°\", f\"Après correction {90*(i+1)}°\")\n","\n","\n","# cv2.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{"id":"tySXvMzS4n5W"},"source":["##Blur"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Toivb9zk4Nlx"},"outputs":[],"source":["def apply_blur(image, blur_kernel=(5, 5)):\n","    # Appliquer un flou gaussien léger\n","    blurred_image = cv2.GaussianBlur(image, blur_kernel, 0)\n","\n","    return blurred_image"]},{"cell_type":"markdown","metadata":{"id":"7KfvHjlD5NCi"},"source":["##Scale"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xjjj44pW5Mig"},"outputs":[],"source":["def scale_image_to_size(image, target_width=600, target_height=300):\n","    resized_image = cv2.resize(image, (target_width, target_height))\n","    return resized_image"]},{"cell_type":"markdown","metadata":{"id":"eMI2D4Ep_AgM"},"source":["## Remove snow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfBW1XZA--7m"},"outputs":[],"source":["import numpy as np\n","import cv2\n","from skimage.morphology import remove_small_objects\n","import matplotlib.pyplot as plt\n","\n","def remove_snow(binary_image, min_size=500):\n","    \"\"\"\n","    Supprimer le bruit de neige dans une image binaire en supprimant les petits objets.\n","\n","    Parameters:\n","    - image : ndarray\n","        L'image binaire (0 et 1).\n","    - min_size : int\n","        La taille minimale d'un objet à conserver (en nombre de pixels).\n","\n","    Returns:\n","    - image : ndarray\n","        L'image avec le bruit de neige supprimé.\n","    \"\"\"\n","\n","    binary_image = binary_image.astype(bool)\n","    # Supprimer les petits objets\n","    cleaned_image = remove_small_objects(binary_image, min_size=min_size)\n","\n","    # Convertir l'image traitée de retour à l'échelle\n","    return (cleaned_image).astype(np.uint8)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"daEAWlBQ_qz2"},"source":["## Fill holes"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"dbnFFh-6_qX7","executionInfo":{"status":"ok","timestamp":1736095282415,"user_tz":-60,"elapsed":207,"user":{"displayName":"Romain","userId":"08376042861121468199"}}},"outputs":[],"source":["import numpy as np\n","from scipy import ndimage\n","\n","import numpy as np\n","from scipy import ndimage\n","\n","def fill_holes(image, max_hole_size=None, structure=None, origin=0):\n","    \"\"\"\n","    Remplir les trous dans une image binaire, avec une limite sur la taille des trous à remplir.\n","\n","    Parameters:\n","    - image : array_like\n","        L'image binaire avec des objets et des trous à remplir.\n","    - max_hole_size : int, optionnel\n","        La taille maximale des trous à remplir (en pixels). Si None, tous les trous seront remplis.\n","    - structure : array_like, optionnel\n","        L'élément structurant utilisé dans la dilatation. Si None, un élément structurant par défaut est utilisé.\n","    - origin : int, optionnel\n","        Position de l'élément structurant. Par défaut, `origin=0`.\n","\n","    Returns:\n","    - ndarray\n","        L'image avec les trous remplis.\n","    \"\"\"\n","    # Assurez-vous que l'image d'entrée est un tableau numpy binaire\n","    image = np.asarray(image)\n","\n","    # Vérifier si l'image est binaire, sinon la convertir\n","    if image.max() > 1:\n","        _, image = cv2.threshold(image, 127, 1, cv2.THRESH_BINARY)\n","\n","    # Convertir l'image en type booléen (True pour l'objet, False pour le fond)\n","    image = image.astype(bool)\n","\n","    # Identifier les trous (zones de fond connectées entourées par des objets)\n","    inverted_image = ~image\n","    labeled_holes, num_features = ndimage.label(inverted_image, structure=structure)\n","\n","    # Calculer la taille de chaque trou\n","    hole_sizes = np.bincount(labeled_holes.ravel())\n","\n","    # Créer une image pour les trous qui respectent la contrainte de taille\n","    allowed_holes = np.zeros_like(labeled_holes, dtype=bool)\n","\n","    for i in range(1, len(hole_sizes)):  # Ignore le fond (label 0)\n","        if max_hole_size is None or hole_sizes[i] <= max_hole_size:\n","            allowed_holes[labeled_holes == i] = True\n","\n","    # Remplir uniquement les trous valides\n","    filled_image = image | allowed_holes\n","\n","    # Convertir l'image booléenne en image binaire (0 ou 1)\n","    return filled_image.astype(np.uint8)\n"]},{"cell_type":"markdown","metadata":{"id":"IvaujRmO9pg8"},"source":["#Pre traitement"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"x_7KOqzK034z","executionInfo":{"status":"ok","timestamp":1736095360193,"user_tz":-60,"elapsed":163,"user":{"displayName":"Romain","userId":"08376042861121468199"}}},"outputs":[],"source":["def process_image_1(image):\n","    return image\n","\n","# Function to apply all transformations to a given image\n","def process_image_2(image):\n","\n","    # 1. Appliquer process_1 sur l'image\n","    image = process_image_1(image)\n","\n","    # 2. Orienter l'image (corriger la rotation)\n","    # oriented_image = correct_image_orientation_using_lines(image)\n","\n","    # 3. Appliquer le deskewing\n","    deskewed_image = deskew_image(image)\n","\n","    # 4. Appliquer le flou léger\n","    blurred_image = apply_blur(deskewed_image)\n","\n","    # 5. Redimensionner l'image\n","    resized_image = scale_image_to_size(blurred_image)\n","\n","    return resized_image\n","\n","def process_image_3(image):\n","\n","    # deskewed_image = deskew_image(image)\n","\n","    resized_image = scale_image_to_size(image)\n","\n","    sauvola_image = sauvola_binarization(resized_image, window_size=35, k=0.08, R=128)\n","\n","    return sauvola_image\n","\n","def process_image_4(image):\n","    # 1. Appliquer process_3 sur l'image\n","    image = process_image_3(image)\n","\n","    removed_snow = remove_snow(image,min_size=5)\n","\n","    filled = fill_holes(removed_snow,500)\n","\n","\n","    return filled\n"]},{"cell_type":"code","source":["input_dir = '/content/drive/MyDrive/Project/Deep Learning/etiquettes_pre_traitees/unprocessed_etiquettes'\n","output_dir_2 = '/content/drive/MyDrive/Project/Deep Learning/etiquettes_pre_traitees/etiquettes_process_2'\n","output_dir_3 = '/content/drive/MyDrive/Project/Deep Learning/etiquettes_pre_traitees/etiquettes_process_3'\n","output_dir_4 = '/content/drive/MyDrive/Project/Deep Learning/etiquettes_pre_traitees/etiquettes_process_4'\n","\n","def save_image(image, directory, filename):\n","    path = os.path.join(directory, filename)\n","    cv2.imwrite(path, image)\n","\n","for directory in [output_dir_2, output_dir_3, output_dir_4]:\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","image_files = [f for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n","for image_file in image_files:\n","    image_path = os.path.join(input_dir, image_file)\n","    image = cv2.imread(image_path)\n","    processed_2 = process_image_2(image)\n","    save_image(processed_2, output_dir_2, image_file)\n","    processed_3 = process_image_3(image)\n","    save_image((1-processed_3)*255, output_dir_3, image_file)\n","    processed_4 = process_image_4(image)\n","    save_image((1-processed_4)*255, output_dir_4, image_file)\n","\n","print(\"Done\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujnKP-VhzYX7","executionInfo":{"status":"ok","timestamp":1736095380282,"user_tz":-60,"elapsed":19054,"user":{"displayName":"Romain","userId":"08376042861121468199"}},"outputId":"f150d335-3075-40e7-b9c1-552deed4b77a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Done\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}